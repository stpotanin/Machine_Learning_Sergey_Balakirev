{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMD/bVKLgDZBlZ/uAdPxYfi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1370090/step/8"
      ],
      "metadata": {
        "id": "b2Es7YLJC1Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Исходная функция, которую нужно аппроксимировать моделью a(x)\n",
        "def func(x):\n",
        "    return 0.1 * x**2 - np.sin(x) + 5.\n",
        "\n",
        "# Модель\n",
        "a = lambda x, w: w[0] + w[1] * x + w[2] * x**2 + w[3] * x**3\n",
        "\n",
        "# Градиент функции потерь\n",
        "dQ = lambda w: 2 * np.mean([(a(xi, w) - func(xi)) * np.array([1., xi, xi**2, xi**3]) for xi in x], axis=0)\n",
        "\n",
        "# Значения по оси абсцисс\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = func(x)\n",
        "\n",
        "# Параметры\n",
        "sz = len(x)\n",
        "eta = np.array([0.1, 0.01, 0.001, 0.0001])  # Шаг обучения для каждого параметра w0, w1, w2, w3\n",
        "w = np.array([0., 0., 0., 0.])  # Начальные значения параметров модели\n",
        "N = 200  # Число итераций градиентного алгоритма\n",
        "\n",
        "# Градиентный спуск\n",
        "for _ in range(N):\n",
        "    w -= eta * dQ(w)  # Обновление параметров\n",
        "\n",
        "# Вычисление функции потерь\n",
        "Q = np.mean([(a(xi, w) - func(xi))**2 for xi in x])\n",
        "\n",
        "print('Q =', Q)\n",
        "print('w =', w)\n"
      ],
      "metadata": {
        "id": "XvDM9nLsMNzu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb47ebed-31b4-47c3-aab9-a2c7e2335fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q = 0.13061463936073703\n",
            "w = [ 4.98645739 -0.41780964  0.10273088  0.0317247 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Матрица признаков заменит функцию $a(x)$ для модели"
      ],
      "metadata": {
        "id": "2H6Nlx3cic2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Функции\n",
        "f = lambda x: .1 * x**2 - np.sin(x) + 5\n",
        "dQ = lambda x, w: 2 * (x @ w - y) @ x / len(x)\n",
        "\n",
        "# Параметры\n",
        "eta = np.array([0.1, 0.01, 0.001, 0.0001])  # Шаг обучения для каждого параметра w0, w1, w2, w3\n",
        "w = np.array([0., 0., 0., 0.])  # Начальные значения параметров модели\n",
        "N = 200                         # Число итераций градиентного алгоритма\n",
        "\n",
        "# Данные\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = f(x)\n",
        "X = np.vander(x, len(w), increasing=True)   # Матрица Вандермонда\n",
        "\n",
        "# Градиентный спуск\n",
        "for _ in range(N):\n",
        "    w -= eta * dQ(X, w)  # Обновление параметров\n",
        "\n",
        "# Качество\n",
        "Q = np.mean((X @ w - y)**2)\n",
        "\n",
        "print('Q =', Q)\n",
        "print('w =', w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgAUeFgivlO",
        "outputId": "0401c62c-9485-4fad-9676-b8dad6f26de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q = 0.13061463936073703\n",
            "w = [ 4.98645739 -0.41780964  0.10273088  0.0317247 ]\n"
          ]
        }
      ]
    }
  ]
}
