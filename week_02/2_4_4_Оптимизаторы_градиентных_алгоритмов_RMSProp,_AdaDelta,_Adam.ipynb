{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgtcM0Q4VA9BXA7vtVCLRj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1370093/step/4\n",
        "\n",
        "http://mech.math.msu.su/~vvb/MasterAI/GradientDescent.html"
      ],
      "metadata": {
        "id": "z6JMgGMm2cEq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метод импульсов\n",
        "Метод импульсов — это техника оптимизации, используемая в машинном обучении, особенно в контексте градиентного спуска. Он помогает ускорить сходимость алгоритмов за счет учета прошлых градиентов, что позволяет сгладить обновления параметров и преодолеть проблемы, связанные с шумными градиентами и колебаниями.\n",
        "\n",
        "### Основная Формула\n",
        "\n",
        "$$\n",
        "S = \\gamma \\cdot S + \\eta \\cdot \\nabla Q(w)\n",
        "$$\n",
        "\n",
        "где:\n",
        "- **$ S $** — это значение импульса (или накопленный градиент), которое обновляется на каждом шаге.\n",
        "- **$ \\gamma $** — коэффициент инерции, который определяет, насколько сильно предыдущее значение импульса влияет на текущее обновление. Обычно его значение находится в диапазоне от 0 до 1 (например, 0.9).\n",
        "- **$ \\eta $** — скорость обучения, контролирующая величину шага обновления.\n",
        "- **$ \\nabla Q(w) $** — градиент функции потерь относительно параметров.\n",
        "\n",
        "### Преимущества Метода Импульсов\n",
        "\n",
        "1. **Ускорение Сходимости**: Метод помогает быстрее достигать локального минимума, особенно в сложных многомерных задачах. Это достигается за счет сглаживания траектории оптимизации и уменьшения колебаний.\n",
        "\n",
        "2. **Устойчивость к Шуму**: Импульс позволяет более эффективно обрабатывать шумные градиенты, что особенно важно в стохастическом градиентном спуске.\n",
        "\n",
        "3. **Сглаживание Обновлений**: Использование предыдущих значений градиентов помогает избежать резких изменений в процессе обучения, что делает алгоритм более стабильным.\n",
        "\n",
        "### Основные Цели Метода Импульсов\n",
        "\n",
        "1. **Устойчивость к Колебаниям**: Метод импульсов помогает сгладить колебания в процессе оптимизации, что особенно важно в задачах с высоким уровнем шума. Это достигается за счет учета прошлых градиентов, что позволяет избежать резких изменений в обновлениях.\n",
        "\n",
        "2. **Преодоление Плоских Участков**: В плоских участках функции потерь, где градиент близок к нулю, стандартный градиентный спуск может застрять. Импульс помогает \"продолжать движение\" даже в таких ситуациях, позволяя алгоритму преодолевать эти участки и двигаться к более низким значениям функции потерь.\n",
        "\n",
        "3. **Сглаживание Траектории Оптимизации**: Использование инерции (параметра $ \\gamma $) позволяет алгоритму сохранять скорость и направление, что помогает ему \"перепрыгивать\" через локальные минимумы и находить более глубокие минимумы функции потерь.\n",
        "\n",
        "4. **Эффективность Обновлений**: Метод импульсов позволяет делать более обоснованные шаги при обновлении параметров, что приводит к более быстрой сходимости и лучшей производительности модели.\n",
        "\n",
        "### Как Работает Метод Импульсов\n",
        "\n",
        "В методе импульсов используется накопленный градиент вместо обычного градиента. Это позволяет алгоритму учитывать не только текущее значение градиента, но и информацию о предыдущих градиентах, что значительно улучшает стабильность и скорость сходимости.\n",
        "\n",
        "1. **Накопление Градиентов**:\n",
        "   - В отличие от стандартного стохастического градиентного спуска (SGD), который использует только текущее значение градиента для обновления параметров, метод импульсов накапливает информацию о предыдущих градиентах. Это делается с помощью экспоненциального скользящего среднего, что позволяет сохранять направление движения в пространстве параметров.\n",
        "\n",
        "2. **Формула Обновления**:\n",
        "   - Обновление параметров в методе импульсов может быть записано как:\n",
        "     $$\n",
        "     v_t = \\gamma \\cdot v_{t-1} + \\eta \\cdot \\nabla Q(w)\n",
        "     $$\n",
        "     $$\n",
        "     w = w - v_t\n",
        "     $$\n",
        "   - Здесь\n",
        "   \n",
        "   $ v_t $ — это накопленный градиент (или импульс),\n",
        "   \n",
        "   $ \\gamma $ — коэффициент инерции, а\n",
        "\n",
        "   $ \\eta $ — скорость обучения.\n"
      ],
      "metadata": {
        "id": "3zBUz16DVBDN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метод ускоренного градиента Нестерова (Nesterov Accelerated Gradient, NAG)\n",
        "\n",
        "$$\n",
        "S = \\gamma \\cdot S + \\eta \\cdot \\nabla Q(w - \\gamma \\cdot S)\n",
        "$$\n",
        "\n",
        "Этот метод использует концепцию импульса и позволяет \"заглядывать вперед\" при вычислении градиента, что способствует более эффективной оптимизации.\n",
        "\n",
        "### Основные характеристики метода Нестерова:\n",
        "\n",
        "1. **Импульс**: Метод использует накопленный импульс, что позволяет сглаживать обновления и уменьшать влияние случайных колебаний градиентов.\n",
        "\n",
        "2. **Заглядывание Вперед**: Вместо вычисления градиента в текущей позиции, метод оценивает его в предполагаемой следующей позиции, что позволяет делать более обоснованные шаги в направлении минимума.\n",
        "\n",
        "3. **Улучшенная Сходимость**: NAG часто демонстрирует более высокие скорости сходимости по сравнению с обычными методами градиентного спуска и стандартным импульсом, что делает его особенно эффективным для задач машинного обучения и оптимизации.\n",
        "\n",
        "### Математическая Формулировка\n",
        "\n",
        "Метод Нестерова можно выразить следующим образом:\n",
        "\n",
        "1. Сначала вычисляется \"предполагаемая\" позиция:\n",
        "   $$\n",
        "   w_{lookahead} = w - \\gamma \\cdot S\n",
        "   $$\n",
        "\n",
        "2. Затем вычисляется градиент в этой позиции:\n",
        "   $$\n",
        "   g = \\nabla Q(w_{lookahead})\n",
        "   $$\n",
        "\n",
        "3. Обновление импульса и параметров:\n",
        "   $$\n",
        "   S = \\gamma \\cdot S - \\eta \\cdot g\n",
        "   $$\n",
        "   $$\n",
        "   w = w + S\n",
        "   $$\n",
        "В формуле\n",
        "\n",
        "$$\n",
        "S = \\gamma \\cdot S + \\eta \\cdot \\nabla Q(w - \\gamma \\cdot S)\n",
        "$$\n",
        "\n",
        "параметр **$ \\gamma $** представляет собой коэффициент инерции, который используется для управления влиянием предыдущих значений на текущее обновление. Обычно его значение выбирается в диапазоне от 0 до 1, и часто устанавливается близким к 0.9.\n",
        "\n",
        "### Основные функции параметра $ \\gamma $:\n",
        "\n",
        "1. **Инерция**: Параметр $ \\gamma $ определяет, насколько сильно предыдущее значение $ S $ влияет на текущее обновление. Чем ближе значение $ \\gamma $ к 1, тем больше влияние предыдущего значения, что помогает сгладить обновления и уменьшить колебания.\n",
        "\n",
        "2. **Управление Шагом Обновления**: При использовании метода Нестерова, этот параметр помогает улучшить сходимость алгоритма, позволяя \"заглядывать вперед\" и учитывать информацию о предыдущих градиентах.\n",
        "\n",
        "3. **Сглаживание Обновлений**: Использование инерции помогает избежать резких изменений в процессе обучения, что делает алгоритм более устойчивым к шуму и колебаниям в данных.\n"
      ],
      "metadata": {
        "id": "38MT6vfZQLkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RMSProp\n",
        "\n",
        "RMSProp (Root Mean Square Propagation) — это адаптивный метод градиентного спуска, который использует экспоненциально взвешенное скользящее среднее квадратов градиентов для адаптации скорости обучения. Формулы ниже соответствуют обновлениям параметров в этом методе, где учитываются как текущие градиенты, так и их накопленные значения для улучшения сходимости алгоритма.\n",
        "\n",
        "Представленные формулы\n",
        "$$\n",
        "G = \\alpha \\cdot G + (1 - \\alpha) \\cdot \\nabla Q(w) \\odot \\nabla Q(w)\n",
        "$$ и\n",
        "$$\n",
        "S = \\eta \\cdot \\frac{\\nabla Q(w)}{\\sqrt{G} + \\epsilon}\n",
        "$$\n",
        "относятся к методам оптимизации, использующим градиентный спуск с адаптивными моментами.\n",
        "\n",
        "### Объяснение Формул\n",
        "\n",
        "1. **Первая Формула**: $$ G = \\alpha \\cdot G + (1 - \\alpha) \\cdot \\nabla Q(w) \\odot \\nabla Q(w) $$\n",
        "   - Здесь $ G $ представляет собой накопленный градиент, который обновляется с учетом предыдущего значения $ G $ и текущего градиента функции потерь $ \\nabla Q(w) $.\n",
        "   - Параметр $ \\alpha $ контролирует, насколько сильно текущее значение градиента влияет на обновление. Это позволяет сглаживать обновления и уменьшать шум.\n",
        "\n",
        "2. **Вторая Формула** $$ S = \\eta \\cdot \\frac{\\nabla Q(w)}{\\sqrt{G} + \\epsilon}\n",
        " $$ :\n",
        "\n",
        "   - **$ S $**: Это итоговое значение, которое будет использоваться для обновления параметров модели.\n",
        "   - **$ \\eta $**: Скорость обучения, которая контролирует, насколько сильно будут изменяться параметры на каждом шаге.\n",
        "   - **$ \\nabla Q(w) $**: Градиент функции потерь относительно параметров $ w $.\n",
        "   - **$ G $**: Квадрат градиента, который накапливается с помощью экспоненциального скользящего среднего (например, в методах RMSProp или Adam).\n",
        "   - **$ \\epsilon $**: Маленькое положительное значение, добавляемое для предотвращения деления на ноль и обеспечения численной стабильности.\n",
        "\n",
        "**Зачем Нужен Знаменатель?**\n",
        "   - Знаменатель $ \\sqrt{G} + \\epsilon $ нормализует градиент. Это позволяет адаптировать скорость обучения в зависимости от величины градиента. Если градиент велик, то значение в знаменателе также будет большим, что приведет к меньшему обновлению параметров. В случае небольших градиентов знаменатель будет меньше, что позволит делать более значительные шаги.\n",
        "   - Это помогает избежать проблем с переобучением и обеспечивает более стабильное и быстрое обучение."
      ],
      "metadata": {
        "id": "T3vR0KnE2wl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zbhSWvL2VBU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Квадрат градиента в формуле\n",
        "\n",
        "$$\n",
        "G = \\alpha \\cdot G + (1 - \\alpha) \\cdot \\nabla Q(w) \\odot \\nabla Q(w)\n",
        "$$\n",
        "\n",
        "действительно используется для нормализации, но его роль выходит за пределы просто нормализации. Давайте подробнее разберем, как именно квадрат градиента влияет на процесс оптимизации.\n",
        "\n",
        "## Роль Квадрата Градиента\n",
        "\n",
        "1. **Нормализация и Адаптация**:\n",
        "   - Квадрат градиента позволяет адаптировать скорость обучения в зависимости от величины градиентов. Когда градиенты велики, их квадраты будут также большими, что приведет к меньшему обновлению параметров. Это помогает избежать слишком больших шагов в направлении, где функция потерь меняется резко, что может привести к нестабильности.\n",
        "\n",
        "2. **Устойчивость к Шуму**:\n",
        "   - Возведение в квадрат помогает сгладить влияние случайных колебаний градиентов. Даже если текущий градиент имеет отрицательное значение, его квадрат будет положительным, что позволяет избежать проблем с направлением при накоплении информации о градиентах.\n",
        "\n",
        "3. **Сглаживание Обновлений**:\n",
        "   - Использование экспоненциального скользящего среднего для накопления квадратов градиентов позволяет более эффективно учитывать последние изменения в градиентах, придавая им больший вес. Это помогает алгоритму быстрее реагировать на изменения в функции потерь.\n",
        "\n",
        "4. **Избежание Затухания Градиента**:\n",
        "   - В глубоких нейронных сетях проблема затухания градиента может привести к тому, что обучение замедляется или останавливается. Квадраты градиентов помогают поддерживать более стабильные обновления параметров, особенно на ранних этапах обучения."
      ],
      "metadata": {
        "id": "Zn5kgL-WH7-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Диагональный метод Левенберга-Марквардта\n",
        "\n",
        "**Диагональный метод Левенберга-Марквардта** (или **метод Левенберга-Марквардта**) — это алгоритм оптимизации, предназначенный для решения задач наименьших квадратов. Он является модификацией классического метода Гаусса-Ньютона и сочетает в себе элементы градиентного спуска и метода доверительных областей. Этот метод особенно полезен в задачах, где требуется минимизация функции [невязки](https://ru.ruwiki.ru/wiki/%D0%9D%D0%B5%D0%B2%D1%8F%D0%B7%D0%BA%D0%B0), например, в регрессионных моделях.\n",
        "\n",
        "### Основная Формула\n",
        "\n",
        "Формула для обновления параметров в диагональном методе Левенберга-Марквардта выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "S = \\eta \\cdot \\left( \\frac{\\partial^2 L_i(w)}{\\partial w^2} + \\mu \\right)^{-1} \\cdot \\frac{\\partial L_i(w)}{\\partial w}\n",
        "$$\n",
        "\n",
        "где:\n",
        "- **$$ S $$** — это вектор обновления параметров.\n",
        "- **$$ \\eta $$** — скорость обучения.\n",
        "- **$$ \\frac{\\partial^2 L_i(w)}{\\partial w^2} $$** — матрица вторых производных (гессиан) функции потерь $$ L_i(w) $$.\n",
        "- **$$ \\mu $$** — коэффициент регуляризации, который добавляется для улучшения численной стабильности и предотвращения вырождения матрицы.\n",
        "\n",
        "### Принципы Работы Алгоритма\n",
        "\n",
        "1. **Комбинация Гаусса-Ньютона и Градиентного Спуска**:\n",
        "   - Метод Левенберга-Марквардта сочетает идеи метода Гаусса-Ньютона (который использует информацию о кривизне функции через гессиан) и градиентного спуска (который использует только информацию о градиенте). Это позволяет более эффективно находить минимум функции потерь.\n",
        "\n",
        "2. **Регуляризация**:\n",
        "   - Параметр $$ \\mu $$ служит для корректировки гессиана, что помогает избежать проблем с вырождением матрицы, особенно когда функция потерь имеет плоские участки или когда градиенты малы.\n",
        "\n",
        "3. **Диагональная Матрица Гессе**:\n",
        "   - В диагональном методе предполагается, что гессиан является диагональной матрицей. Это значительно упрощает вычисления и уменьшает вычислительные затраты, так как инверсия диагональной матрицы требует всего лишь деления на элементы главной диагонали.\n",
        "\n",
        "### Алгоритм\n",
        "\n",
        "1. **Инициализация**: Задаются начальные значения параметров и коэффициента регуляризации.\n",
        "2. **Вычисление Градиента и Гессиана**: На каждом шаге вычисляются градиенты и гессиан функции потерь.\n",
        "3. **Обновление Параметров**: Параметры обновляются по формуле, используя рассчитанные градиенты и гессиан.\n",
        "4. **Проверка Условия Остановки**: Алгоритм продолжается до тех пор, пока не будет достигнуто заданное условие остановки (например, изменение функции потерь меньше определенного порога).\n",
        "\n",
        "### Преимущества\n",
        "\n",
        "- **Скорость Сходимости**: Метод Левенберга-Марквардта часто быстрее сходится к локальному минимуму по сравнению с простыми методами градиентного спуска.\n",
        "- **Устойчивость к Шуму**: Регуляризация помогает улучшить устойчивость алгоритма к шумам в данных.\n",
        "- **Эффективность Вычислений**: Использование диагональной матрицы гессиана значительно снижает вычислительные затраты.\n",
        "\n",
        "### Заключение\n",
        "\n",
        "Диагональный метод Левенберга-Марквардта является мощным инструментом для решения задач оптимизации в машинном обучении и статистике. Его способность эффективно комбинировать информацию о градиентах и кривизне делает его популярным выбором для задач нелинейной регрессии и других приложений, требующих минимизации функций потерь.\n",
        "\n",
        "Citations:\n",
        "[1] https://ya.ru/neurum/c/nauka-i-obrazovanie/q/chto_takoe_diagonalnyy_metod_levenbergamarkvardta_7082e277\n",
        "[2] https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D0%B1%D0%B5%D1%80%D0%B3%D0%B0_%E2%80%94_%D0%9C%D0%B0%D1%80%D0%BA%D0%B2%D0%B0%D1%80%D0%B4%D1%82%D0%B0\n",
        "[3] http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D0%B1%D0%B5%D1%80%D0%B3%D0%B0-%D0%9C%D0%B0%D1%80%D0%BA%D0%B2%D0%B0%D1%80%D0%B4%D1%82%D0%B0\n",
        "[4] https://yandex.ru/q/machine-learning/12397577985/\n",
        "[5] https://proproprogs.ru/ml/ml-optimizatory-gradientnyh-algoritmov-rmsprop-adadelta-adam-nadam"
      ],
      "metadata": {
        "id": "LzFGZ0YrcfsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Метод доверительных областей\n",
        "можно рассматривать как подход, при котором большая задача оптимизации разбивается на множество меньших задач.\n",
        "\n",
        "## Идея Разделения на Меньшие Задачи\n",
        "\n",
        "1. **Адаптивная Аппроксимация**:\n",
        "   - Вместо того чтобы пытаться минимизировать сложную функцию потерь напрямую, метод доверительных областей создает более простую функцию (аппроксимацию), которая хорошо описывает поведение исходной функции в ограниченной области вокруг текущего решения. Это позволяет сосредоточиться на локальных изменениях, которые легче анализировать и минимизировать.\n",
        "\n",
        "2. **Итеративный Процесс**:\n",
        "   - На каждом шаге алгоритма:\n",
        "     - Определяется текущая точка (набор параметров).\n",
        "     - Вычисляется градиент и/или гессиан (вторые производные) в этой точке.\n",
        "     - Создается доверительная область, в которой функция хорошо аппроксимируется.\n",
        "     - Минимизируется аппроксимированная функция внутри этой области, что дает новое значение параметров.\n",
        "     - Если новое значение параметров улучшает функцию потерь, область может быть увеличена для следующего шага; если нет — может быть уменьшена.\n",
        "\n",
        "3. **Многоразовые Минимизации**:\n",
        "   - Таким образом, вместо одной глобальной задачи оптимизации мы решаем множество локальных задач минимизации. Каждая из этих задач фокусируется на небольшом участке пространства параметров, что делает процесс более управляемым и эффективным.\n",
        "\n",
        "## Преимущества Подхода\n",
        "\n",
        "- **Устойчивость**: Поскольку каждая итерация фокусируется на малой области, это позволяет лучше контролировать процесс и избегать резких изменений.\n",
        "- **Скорость**: Минимизация аппроксимированной функции обычно требует меньше вычислительных ресурсов по сравнению с непосредственной минимизацией сложной функции потерь.\n",
        "- **Гибкость**: Метод может адаптироваться к различным функциям и их особенностям, что делает его полезным в широком круге задач.\n",
        "\n",
        "В методе доверительных областей, как правило, используется одна и та же форма апроксимирующей функции, но с изменяющимися параметрами. Давайте подробнее рассмотрим этот процесс.\n",
        "\n",
        "### Апроксимация в Методе Доверительных Областей\n",
        "\n",
        "1. **Форма Аппроксимации**:\n",
        "   - Обычно в рамках метода доверительных областей используется квадратичная модель для аппроксимации целевой функции. Это значит, что на каждом шаге алгоритма предполагается, что функция может быть представлена в виде параболы (или поверхности второго порядка) в пределах доверительной области.\n",
        "   - Эта форма модели позволяет эффективно использовать информацию о градиенте и гессиане функции потерь.\n",
        "\n",
        "2. **Изменение Параметров**:\n",
        "   - Параметры модели (например, коэффициенты квадратичной функции) обновляются на каждой итерации в зависимости от текущих значений градиента и гессиана. Таким образом, хотя форма функции остается постоянной (квадратичная), ее параметры изменяются в процессе оптимизации.\n",
        "   - Размер доверительной области также может изменяться в зависимости от того, насколько хорошо аппроксимация соответствует реальной функции в данной области.\n",
        "\n",
        "3. **Выбор Формы Функции**:\n",
        "   - В некоторых случаях может потребоваться выбрать другую форму апроксимирующей функции, если квадратичная модель оказывается недостаточно точной. Однако это менее распространено в методах доверительных областей, так как использование квадратичной модели обычно обеспечивает хорошую сходимость и стабильность.\n",
        "   - В случае необходимости можно использовать более сложные модели, но это может увеличить вычислительные затраты и сложность алгоритма.\n",
        "\n",
        "В контексте метода доверительных областей и оптимизации, использование параболы для аппроксимации функции потерь связано с анализом знака гессиана, который позволяет понять, является ли функция в данной точке выпуклой или вогнутой.\n",
        "\n",
        "### Парабола и Знак Гессиана\n",
        "\n",
        "1. **Гессиан**:\n",
        "   - Гессиан — это матрица вторых производных функции. Он используется для анализа кривизны функции потерь. Если гессиан положительно определен (все его собственные значения положительны), то функция является выпуклой в данной точке, что указывает на наличие локального минимума.\n",
        "   - Если гессиан отрицательно определен (все собственные значения отрицательны), функция является вогнутой, что указывает на наличие локального максимума.\n",
        "   - Если гессиан имеет как положительные, так и отрицательные собственные значения, функция имеет седловую точку.\n",
        "\n",
        "2. **Использование Параболы**:\n",
        "   - При аппроксимации функции потерь с помощью параболы (квадратичной функции) можно легко определить знак гессиана. Парабола позволяет визуализировать поведение функции в окрестности точки.\n",
        "   - Например, если мы рассматриваем функцию вида $$ f(x) = ax^2 + bx + c $$, то знак $$ a $$ (коэффициент перед $$ x^2 $$) определяет, является ли парабола \"вверх\" (выпуклая) или \"вниз\" (вогнутая). Это напрямую связано со знаком гессиана: если $$ a > 0 $$, то гессиан положителен, и наоборот.\n",
        "\n",
        "3. **Анализ Выпуклости**:\n",
        "   - Используя параболу для аппроксимации, мы можем быстро оценить выпуклость функции в данной области. Это позволяет принимать решения о том, как изменять параметры и шаги обновления в процессе оптимизации.\n",
        "   - Например, если мы видим, что аппроксимация указывает на выпуклость, это может означать, что мы находимся близко к минимуму, и можно увеличить шаг обновления. Если же наблюдается вогнутость, это может сигнализировать о необходимости уменьшить шаг."
      ],
      "metadata": {
        "id": "mcWHPlJBhQIB"
      }
    }
  ]
}
