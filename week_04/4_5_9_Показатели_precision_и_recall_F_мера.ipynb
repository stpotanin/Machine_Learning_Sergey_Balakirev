{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGByi4FPIsbjeJRx7dHtkq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1370106/step/9"
      ],
      "metadata": {
        "id": "llq15muaB9Xj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m31r1Y_BvVc",
        "outputId": "dacf3461-b79b-45af-bc98-a0568126d116"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9722222222222222, 0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# логарифмическая функция потерь: log2​(1+e−{w^T⋅xi​⋅yi}​)\n",
        "loss = lambda w, x, y: np.log2(1 + np.exp(x @ w * y))\n",
        "\n",
        "# её производная вектору w: −e−{w^T⋅xi​⋅yi​⋅x^iT​⋅yi}​​ / ((1+e^{-wT⋅xi​⋅yi}​)⋅ln(2))\n",
        "df = lambda w, x, y: -np.exp(-x @ w * y) * x * y / (1 + np.exp(-x @ w * y)) / np.log(2)\n",
        "\n",
        "data_x = [(5.8, 1.2), (5.6, 1.5), (6.5, 1.5), (6.1, 1.3), (6.4, 1.3), (7.7, 2.0), (6.0, 1.8), (5.6, 1.3), (6.0, 1.6), (5.8, 1.9), (5.7, 2.0), (6.3, 1.5), (6.2, 1.8), (7.7, 2.3), (5.8, 1.2), (6.3, 1.8), (6.0, 1.0), (6.2, 1.3), (5.7, 1.3), (6.3, 1.9), (6.7, 2.5), (5.5, 1.2), (4.9, 1.0), (6.1, 1.4), (6.0, 1.6), (7.2, 2.5), (7.3, 1.8), (6.6, 1.4), (5.6, 2.0), (5.5, 1.0), (6.4, 2.2), (5.6, 1.3), (6.6, 1.3), (6.9, 2.1), (6.8, 2.1), (5.7, 1.3), (7.0, 1.4), (6.1, 1.4), (6.1, 1.8), (6.7, 1.7), (6.0, 1.5), (6.5, 1.8), (6.4, 1.5), (6.9, 1.5), (5.6, 1.3), (6.7, 1.4), (5.8, 1.9), (6.3, 1.3), (6.7, 2.1), (6.2, 2.3), (6.3, 2.4), (6.7, 1.8), (6.4, 2.3), (6.2, 1.5), (6.1, 1.4), (7.1, 2.1), (5.7, 1.0), (6.8, 1.4), (6.8, 2.3), (5.1, 1.1), (4.9, 1.7), (5.9, 1.8), (7.4, 1.9), (6.5, 2.0), (6.7, 1.5), (6.5, 2.0), (5.8, 1.0), (6.4, 2.1), (7.6, 2.1), (5.8, 2.4), (7.7, 2.2), (6.3, 1.5), (5.0, 1.0), (6.3, 1.6), (7.7, 2.3), (6.4, 1.9), (6.5, 2.2), (5.7, 1.2), (6.9, 2.3), (5.7, 1.3), (6.1, 1.2), (5.4, 1.5), (5.2, 1.4), (6.7, 2.3), (7.9, 2.0), (5.6, 1.1), (7.2, 1.8), (5.5, 1.3), (7.2, 1.6), (6.3, 2.5), (6.3, 1.8), (6.7, 2.4), (5.0, 1.0), (6.4, 1.8), (6.9, 2.3), (5.5, 1.3), (5.5, 1.1), (5.9, 1.5), (6.0, 1.5), (5.9, 1.8)]\n",
        "data_y = [-1, -1, -1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, -1, -1, 1, -1, 1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, -1, -1, -1, -1, 1, 1, -1, 1, -1, 1, 1, 1, 1, -1, 1, 1, -1, -1, -1, -1, 1]\n",
        "\n",
        "x_train = np.array([[1, x[0], x[1]] for x in data_x])\n",
        "y_train = np.array(data_y)\n",
        "\n",
        "n_train = len(x_train)  # размер обучающей выборки\n",
        "w = [0.0, 0.0, 0.0]  # начальные весовые коэффициенты\n",
        "nt = np.array([0.5, 0.01, 0.01])  # шаг обучения для каждого параметра w0, w1, w2\n",
        "lm = 0.01  # значение параметра лямбда для вычисления скользящего экспоненциального среднего\n",
        "N = 500  # число итераций алгоритма SGD\n",
        "\n",
        "np.random.seed(0) # генерация одинаковых последовательностей псевдослучайных чисел\n",
        "\n",
        "for _ in range(N):\n",
        "    k = np.random.randint(0, n_train-1) # n_train - размер выборки (массива x_train)\n",
        "    grad = df(w, x_train[k], y_train[k])\n",
        "    w -= nt * grad\n",
        "\n",
        "# Предсказание по модели\n",
        "predict = np.sign(x_train @ w)\n",
        "\n",
        "TP = sum([p == y and p == 1 for p, y in zip(predict, y_train)])\n",
        "TN = sum([p == y and p == -1 for p, y in zip(predict, y_train)])\n",
        "FP = sum([p != y and p == 1 for p, y in zip(predict, y_train)])\n",
        "FN = sum([p != y and p == -1 for p, y in zip(predict, y_train)])\n",
        "\n",
        "precision = TP / (TP + FP)\n",
        "recall = TP / (TP + FN)\n"
      ]
    }
  ]
}
