{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNu7w7qZAoFEDAwro15uWQ7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1370100/step/9"
      ],
      "metadata": {
        "id": "Ol4JvflgdhSB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWWpgEtcddRr",
        "outputId": "c706f3ab-5022-41e8-d1ed-7fd707d6b598"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Параметры распределений двух классов для генерации\n",
        "np.random.seed(0)\n",
        "r1 = 0.7\n",
        "D1 = 1.0\n",
        "mean1 = [-1, -2, -1]\n",
        "V1 = [[D1, D1 * r1, D1*r1*r1], [D1 * r1, D1, D1*r1], [D1*r1*r1, D1*r1, D1]]\n",
        "\n",
        "r2 = 0.5\n",
        "D2 = 2.0\n",
        "mean2 = [1, 2, 1]\n",
        "V2 = [[D2, D2 * r2, D2*r2*r2], [D2 * r2, D2, D2*r2], [D2*r2*r2, D2*r2, D2]]\n",
        "\n",
        "# моделирование обучающей выборки\n",
        "N = 1000\n",
        "x1 = np.random.multivariate_normal(mean1, V1, N).T\n",
        "x2 = np.random.multivariate_normal(mean2, V2, N).T\n",
        "\n",
        "x_train = np.hstack([x1, x2]).T\n",
        "y_train = np.hstack([np.ones(N) * -1, np.ones(N)])\n",
        "\n",
        "# вычисление оценок математических ожиданий\n",
        "mm1 = np.mean(x1.T, axis=0)\n",
        "mm2 = np.mean(x2.T, axis=0)\n",
        "\n",
        "# Вычисление ковариационных матриц для трёх признаков\n",
        "\n",
        "# Для первого класса\n",
        "a = (x1.T - mm1).T\n",
        "VV1 = np.array([\n",
        "    [np.dot(a[0], a[0]) / N, np.dot(a[0], a[1]) / N, np.dot(a[0], a[2]) / N],\n",
        "    [np.dot(a[1], a[0]) / N, np.dot(a[1], a[1]) / N, np.dot(a[1], a[2]) / N],\n",
        "    [np.dot(a[2], a[0]) / N, np.dot(a[2], a[1]) / N, np.dot(a[2], a[2]) / N]\n",
        "])\n",
        "\n",
        "# Для второго класса\n",
        "a = (x2.T - mm2).T\n",
        "VV2 = np.array([\n",
        "    [np.dot(a[0], a[0]) / N, np.dot(a[0], a[1]) / N, np.dot(a[0], a[2]) / N],\n",
        "    [np.dot(a[1], a[0]) / N, np.dot(a[1], a[1]) / N, np.dot(a[1], a[2]) / N],\n",
        "    [np.dot(a[2], a[0]) / N, np.dot(a[2], a[1]) / N, np.dot(a[2], a[2]) / N]\n",
        "])\n",
        "\n",
        "\n",
        "# параметры для гауссовского байесовского классификатора\n",
        "Py1, L1 = 0.5, 1      # вероятности появления классов\n",
        "Py2, L2 = 1 - Py1, 1  # и величины штрафов неверной классификации\n",
        "\n",
        "# Функции:\n",
        "# вычисление вероятности\n",
        "b = lambda x, v, m, l, py: np.log(l * py) - 0.5 * (x - m) @ np.linalg.inv(v) @ (x - m).T - 0.5 * np.log(\n",
        "    np.linalg.det(v))\n",
        "# argmax от вероятностей\n",
        "am = lambda x: np.argmax([b(x, VV1, mm1, L1, Py1), b(x, VV2, mm2, L2, Py2)]) * 2 - 1 # классификатор\n",
        "\n",
        "# Предсказание по модели\n",
        "predict = [am(x) for x in x_train]\n",
        "\n",
        "# Качество\n",
        "Q = sum(predict != y_train)"
      ]
    }
  ]
}
