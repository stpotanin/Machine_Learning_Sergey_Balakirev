{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAEm/UclgW5LG4U7hsq6f8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://habr.com/ru/articles/802435/\n",
        "\n",
        "Формула гауссовского байесовского классификатора для одномерного нормального распределению, где используется стандартная формула плотности вероятности:\n",
        "\n",
        "$$\n",
        "P(x | i) = \\frac{1}{\\sqrt{2\\pi \\sigma_y^2}} \\exp\\left(-\\frac{(x - \\mu_y)^2}{2\\sigma_y^2}\\right)\n",
        "$$\n",
        "\n",
        "Здесь: $ \\mu_y $ — среднее значение, $ \\sigma_y^2 $ — дисперсия.\n",
        "\n",
        "Однако, в случае многомерного нормального распределения, которое используется в гауссовском байесовском классификаторе для многомерных признаков, необходим детерминант ковариационной матрицы . Формула многомерного нормального распределения выглядит следующим образом:\n",
        "\n",
        "$$\n",
        "P(x | y) = \\frac{1}{(2\\pi)^{n/2} |\\Sigma_y|^{1/2}} \\exp\\left(-\\frac{1}{2} (x - \\mu_y)^T \\Sigma_y^{-1} (x - \\mu_y)\\right)\n",
        "$$\n",
        "\n",
        "Здесь:\n",
        "\n",
        "$ n $ — размерность пространства,\n",
        "\n",
        "$ |\\Sigma_y| $ — детерминант ковариационной матрицы $ \\Sigma_y $.\n",
        "\n",
        "**Зачем нужен детерминант?**\n",
        "- **Нормализация**: Детерминант помогает нормализовать вероятность, обеспечивая корректное масштабирование в многомерном пространстве.\n",
        "- **Объем пространства**: Он отражает объем пространства, в котором распределены данные. Если детерминант равен нулю, это указывает на линейную зависимость между признаками и делает распределение неопределенным.\n",
        "\n",
        "Таким образом, детерминант ковариационной матрицы становится критически важным при работе с многомерными данными, что объясняет его отсутствие в формуле для одномерного случая и присутствие в многомерной версии.\n",
        "\n",
        "Citations:\n",
        "[1] https://habr.com/ru/articles/802435/\n",
        "[2] https://proproprogs.ru/ml/ml-gaussovskiy-bayesovskiy-klassifikator\n",
        "[3] http://www.machinelearning.ru/wiki/images/archive/9/98/20120416232216!Voron-ML-Bayes-slides.pdf\n",
        "[4] http://www.machinelearning.ru/wiki/images/archive/c/c1/20160419084316!Voron-ML-Bayes1-slides.pdf\n",
        "[5] https://ru.wikipedia.org/wiki/%D0%9D%D0%B0%D0%B8%D0%B2%D0%BD%D1%8B%D0%B9_%D0%B1%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80\n",
        "[6] https://www.youtube.com/watch?v=OzIGqaizOAo\n",
        "[7] http://www.ccas.ru/voron/download/Bayes.pdf\n",
        "[8] https://www.youtube.com/watch?v=qMndsltzNGA"
      ],
      "metadata": {
        "id": "pjibElLBGoim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Чтобы строго математически вывести детерминант ковариационной матрицы из условных вероятностей, начнем с определения ковариационной матрицы и ее связи с вероятностным распределением.\n",
        "\n",
        "## Определение ковариационной матрицы\n",
        "\n",
        "Ковариационная матрица случайного вектора $ \\mathbf{X} $ с $ n $ компонентами определяется как:\n",
        "\n",
        "$$\n",
        "\\Sigma = \\text{Cov}(\\mathbf{X}) = E\\left[(\\mathbf{X} - E[\\mathbf{X}])(\\mathbf{X} - E[\\mathbf{X}])^T\\right]\n",
        "$$\n",
        "\n",
        "где $ E[\\mathbf{X}] $ — вектор математических ожиданий компонент вектора $ \\mathbf{X} $.\n",
        "\n",
        "## Вывод детерминанта\n",
        "\n",
        "1. **Вероятностное распределение**: Предположим, что вектор $ \\mathbf{X} $ имеет многомерное нормальное распределение с параметрами $ \\mu $ (вектор средних значений) и $ \\Sigma $ (ковариационная матрица):\n",
        "\n",
        "$$\n",
        "P(\\mathbf{x}) = \\frac{1}{(2\\pi)^{n/2} |\\Sigma|^{1/2}} \\exp\\left(-\\frac{1}{2} (\\mathbf{x} - \\mu)^T \\Sigma^{-1} (\\mathbf{x} - \\mu)\\right)\n",
        "$$\n",
        "\n",
        "2. **Условные вероятности**: Рассмотрим условную вероятность $ P(X_i | X_j) $. Для многомерного нормального распределения условные распределения также являются нормальными. Например, если мы хотим выразить $ P(X_i | X_j) $, то оно будет иметь вид:\n",
        "\n",
        "$$\n",
        "P(X_i | X_j) = N(\\mu_{i|j}, \\sigma^2_{i|j})\n",
        "$$\n",
        "\n",
        "где:\n",
        "\n",
        "$$ \\mu_{i|j} = E[X_i] + \\frac{\\text{Cov}(X_i, X_j)}{\\text{Var}(X_j)}(X_j - E[X_j]) $$\n",
        "\n",
        "$$ \\sigma^2_{i|j} = \\sigma^2_{i} - \\frac{\\text{Cov}(X_i, X_j)^2}{\\text{Var}(X_j)} $$\n",
        "\n",
        "3. **Ковариационная матрица**: Если мы имеем несколько переменных, то их совместная ковариация и, следовательно, детерминант ковариационной матрицы описывает взаимосвязи между всеми компонентами. Детерминант ковариационной матрицы показывает, как изменяется объем пространства, охватываемого этими переменными.\n",
        "\n",
        "4. **Детерминант как мера зависимости**: Детерминант ковариационной матрицы:\n",
        "\n",
        "$$\n",
        "|\\Sigma| = |\\text{Cov}(X_1, X_2, ..., X_n)|\n",
        "$$\n",
        "\n",
        "является мерой того, насколько независимы случайные переменные. Если детерминант равен нулю, это означает, что существует линейная зависимость между переменными.\n",
        "\n",
        "## Заключение\n",
        "\n",
        "Таким образом, мы можем увидеть, что детерминант ковариационной матрицы является неотъемлемой частью описания многомерного нормального распределения и его свойств. Он появляется как результат работы с условными вероятностями и описывает взаимосвязь между компонентами случайного вектора.\n",
        "\n",
        "Citations:\n",
        "[1] https://www.youtube.com/watch?v=NJpR8smBEAE\n",
        "\n",
        "[2] https://studizba.com/lectures/matematika/statisticheskie-metody-eksperimentalnyh-issledovaniy/13066-matematicheskie-ozhidaniya-i-kovariacii-vektorov-i-matric.html\n",
        "\n",
        "[3] https://ru.wikipedia.org/wiki/%D0%9A%D0%BE%D0%B2%D0%B0%D1%80%D0%B8%D0%B0%D1%86%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%B0%D1%82%D1%80%D0%B8%D1%86%D0%B0\n",
        "\n",
        "[4] http://itas2012.iitp.ru/pdf/1569602365.pdf\n",
        "\n",
        "[5] https://cyberleninka.ru/article/n/model-markovitsa-matematicheskie-aspekty-i-kompyuternaya-realizatsiya/pdf\n",
        "\n",
        "[6] https://scikit-learn.ru/stable/modules/covariance.html\n",
        "\n",
        "[7] https://www.mathnet.ru/php/archive.phtml?jrnid=at&option_lang=rus&paperid=3252&wshow=paper"
      ],
      "metadata": {
        "id": "uNwMut6sGtsS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "к [уроку](https://stepik.org/lesson/1370099/step/1)"
      ],
      "metadata": {
        "id": "jPMrrpTLtNgu"
      }
    }
  ]
}
