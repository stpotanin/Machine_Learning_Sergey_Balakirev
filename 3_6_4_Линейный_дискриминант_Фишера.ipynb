{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPp5Zwhv2VtysJudVXMxuOK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://stepik.org/lesson/1370101/step/4"
      ],
      "metadata": {
        "id": "_ijVl46jV-sG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCl6arNKV7gJ",
        "outputId": "3e1068bc-1fc7-44a1-ead4-61be9982e57d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# исходные параметры распределений двух классов\n",
        "mean1 = [1, -2]\n",
        "mean2 = [1, 3]\n",
        "r = 0.7\n",
        "D = 2.0\n",
        "V = [[D, D * r],\n",
        "     [D * r, D]]\n",
        "\n",
        "# параметры Py1, L1\n",
        "Py1, L1 = 0.5, 1      # вероятности появления классов\n",
        "Py2, L2 = 1 - Py1, 1  # и величины штрафов неверной классификации\n",
        "\n",
        "# моделирование обучающей выборки\n",
        "N = 1000\n",
        "x1 = np.random.multivariate_normal(mean1, V, N).T\n",
        "x2 = np.random.multivariate_normal(mean2, V, N).T\n",
        "\n",
        "x_train = np.hstack([x1, x2]).T\n",
        "y_train = np.hstack([np.ones(N) * -1, np.ones(N)])\n",
        "\n",
        "# вычисление оценок МО и ковариационной матрицы\n",
        "mm1 = np.mean(x1.T, axis=0)\n",
        "mm2 = np.mean(x2.T, axis=0)\n",
        "\n",
        "a = np.hstack([(x1.T - mm1).T, (x2.T - mm2).T])\n",
        "VV = np.array([[np.dot(a[0], a[0]) / (2*N), np.dot(a[0], a[1]) / (2*N)],\n",
        "                [np.dot(a[1], a[0]) / (2*N), np.dot(a[1], a[1]) / (2*N)]])\n",
        "\n",
        "# Функции:\n",
        "# вычисление вероятности\n",
        "b = lambda x, v, m, l, py: np.log(l * py) - 0.5 * m @ np.linalg.inv(v) @ m + x @ np.linalg.inv(v) @ m\n",
        "# argmax от вероятностей\n",
        "am = lambda x: np.argmax([b(x, VV, mm1, L1, Py1), b(x, VV, mm2, L2, Py2)]) * 2 - 1 # классификатор\n",
        "\n",
        "# Предсказание по модели\n",
        "predict = [am(x) for x in x_train]\n",
        "predict[0], predict[-1]\n",
        "\n",
        "# Качество\n",
        "Q = sum(predict != y_train)\n",
        "Q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Виталий Золотов https://stepik.org/lesson/1370101/step/4?discussion=10354893&thread=solutions&unit=1386291\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Исходные параметры распределений двух классов\n",
        "mean1 = [1, -2]\n",
        "mean2 = [1, 3]\n",
        "r = 0.7\n",
        "D = 2.0\n",
        "V = [[D, D * r], [D * r, D]]\n",
        "\n",
        "# Моделирование обучающей выборки\n",
        "N = 1000\n",
        "x1 = np.random.multivariate_normal(mean1, V, N).T\n",
        "x2 = np.random.multivariate_normal(mean2, V, N).T\n",
        "\n",
        "# Объединение выборок\n",
        "x_train = np.hstack([x1, x2]).T\n",
        "y_train = np.hstack([np.ones(N) * -1, np.ones(N)])\n",
        "\n",
        "# Вычисление оценок математического ожидания и ковариационной матрицы\n",
        "mu1 = np.mean(x1.T, axis=0)  # Математическое ожидание первого класса\n",
        "mu2 = np.mean(x2.T, axis=0)  # Математическое ожидание второго класса\n",
        "\n",
        "# Объединяем данные для вычисления ковариационной матрицы\n",
        "data = np.vstack([x1.T - mu1, x2.T - mu2])\n",
        "\n",
        "# Вычисляем ковариационную матрицу\n",
        "VV = np.cov(data.T)\n",
        "\n",
        "# Обратная ковариационная матрица\n",
        "Sigma_inv = np.linalg.inv(VV)\n",
        "\n",
        "# Параметры для дискриминанта Фишера\n",
        "P_y1 = 0.5  # априорная вероятность класса -1\n",
        "P_y2 = 1 - P_y1  # априорная вероятность класса -1\n",
        "lambda_y1, lambda_y2 = 1, 1  # величины штрафов неверной классификации\n",
        "\n",
        "# Вычисление d1 и d2 для всех обучающих образцов\n",
        "alpha1 = Sigma_inv @ mu1\n",
        "alpha2 = Sigma_inv @ mu2\n",
        "beta1 = np.log(lambda_y1 * P_y1) - 0.5 * mu1 @ Sigma_inv @ mu1\n",
        "beta2 = np.log(lambda_y2 * P_y2) - 0.5 * mu2 @ Sigma_inv @ mu2\n",
        "d1 = x_train @ alpha1 + beta1 # [длинный список] - 4.68\n",
        "d2 = x_train @ alpha2 + beta2\n",
        "\n",
        "# Предсказания классов\n",
        "predict = np.where(d1 > d2, -1, 1)\n",
        "\n",
        "# Подсчет количества ошибок\n",
        "Q = np.sum(predict != y_train)"
      ],
      "metadata": {
        "id": "oTDsU7VJ_g8Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}